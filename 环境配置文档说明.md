# 📚 A100环境配置文档说明

本目录包含了从0开始配置A100 GPU + HSTU训练环境的完整文档和工具。

---

## 📁 文件清单

### 1. 📖 文档

| 文件名 | 说明 | 适用场景 |
|--------|------|----------|
| **A100环境配置完整教程.md** | 最详尽的配置教程 | 首次配置、遇到问题时参考 |
| **快速参考.md** | 快速参考卡片 | 日常使用、查找命令 |
| **环境配置文档说明.md** | 本文档 | 了解文档结构 |

### 2. 🛠️ 工具脚本

| 文件名 | 说明 | 使用方法 |
|--------|------|----------|
| **install_a100_env.sh** | 自动化安装脚本 | `bash install_a100_env.sh` |
| **check_env.sh** | 环境验证脚本 | `bash check_env.sh` |

---

## 🚀 使用流程

### 方案1: 自动化安装 (推荐)

适合：快速配置、对Linux脚本熟悉的用户

```bash
# 1. 下载项目
git clone <repo_url>
cd recsys-examples-main

# 2. 运行自动化安装脚本
bash install_a100_env.sh

# 3. 验证安装
conda activate hstu_a100
bash check_env.sh

# 4. 准备数据和训练 (如果验证通过)
cd examples/hstu
python preprocessor.py --dataset_name ml-20m
```

**时间**: 约1.5-2小时 (取决于硬件和网络)

---

### 方案2: 手动安装

适合：需要自定义配置、遇到自动化脚本问题的用户

```bash
# 1. 阅读完整教程
打开 A100环境配置完整教程.md

# 2. 按照教程逐步执行
# - 第1节: 硬件和系统检查
# - 第2节: CUDA工具链安装
# - 第3节: 创建Conda环境
# - ...
# - 第9节: 运行训练

# 3. 每完成一个大步骤，运行验证脚本
bash check_env.sh

# 4. 遇到问题时，查看"常见问题排查"章节
```

**时间**: 约2-3小时 (包括理解和排查问题)

---

## 📖 详细文档介绍

### A100环境配置完整教程.md

**内容概览**：
1. ✅ 硬件和系统检查 - 如何确认GPU型号和计算能力
2. ✅ CUDA工具链安装 - 安装CUDA Toolkit和编译工具
3. ✅ 创建Conda环境 - Python环境配置
4. ✅ 安装PyTorch - 匹配CUDA版本的PyTorch安装
5. ✅ 编译依赖库 - FBGEMM_GPU、TorchRec、Megatron-Core
6. ✅ 编译CUDA加速模块 - HSTU Attention、Dynamic Embeddings、训练算子
7. ✅ 验证安装 - 完整的功能测试
8. ✅ 数据准备 - 下载和处理数据集
9. ✅ 运行训练 - 启动训练脚本
10. ✅ 常见问题排查 - 10+个常见问题的解决方案
11. ✅ 性能优化建议 - 充分利用A100性能
12. ✅ 完整安装脚本 - 一键安装脚本源码
13. ✅ 总结 - 检查清单和预计时间

**特点**：
- 📝 每个步骤都有详细的命令和说明
- 🔍 包含"期望输出"和验证方法
- ⚠️ 标注了关键注意事项
- 🐛 提供了详细的问题排查步骤
- 📊 包含时间和资源估算

**适用场景**：
- 首次配置环境
- 遇到编译错误需要排查
- 需要理解每个步骤的原理
- 自定义配置需求

---

### 快速参考.md

**内容概览**：
- ⚡ 一键安装命令
- 📝 关键检查命令 (GPU、CUDA、Python环境)
- 🔧 手动安装步骤 (浓缩版)
- 🏃 运行训练命令
- 🐛 快速问题排查
- 📊 关键配置参数
- 📈 性能优化建议
- ⏱️ 预计时间和资源
- 📚 重要文件位置
- 🔗 有用的链接
- ✅ 完整验证脚本

**特点**：
- 📄 单页参考卡片
- 🔍 快速查找命令
- 💡 突出关键信息
- 🎯 直接给出解决方案

**适用场景**：
- 日常使用快速查找命令
- 回顾关键配置参数
- 快速排查常见问题
- 作为备忘录使用

---

## 🛠️ 工具脚本介绍

### install_a100_env.sh

**功能**：
- 🔍 自动检查GPU型号和计算能力
- 📦 自动安装所有依赖库
- ⚙️ 自动编译CUDA加速模块
- ✅ 自动验证安装结果
- 📝 详细的进度提示和日志

**使用方法**：
```bash
# 1. 确保脚本有执行权限
chmod +x install_a100_env.sh

# 2. 运行脚本
bash install_a100_env.sh

# 3. 按照提示输入项目路径
# 例如: /home/user/recsys-examples-main

# 4. 等待安装完成 (约1.5-2小时)
```

**特性**：
- ✅ 自动检测已安装的组件，避免重复安装
- ✅ 编译失败时自动调整并行数
- ✅ 彩色输出，清晰的进度提示
- ✅ 每个步骤都有验证
- ✅ 完成后提供下一步操作指引

**适用场景**：
- 全新系统配置
- 快速部署到多台机器
- 自动化CI/CD流程

---

### check_env.sh

**功能**：
- 🔍 检查conda环境
- 🔍 检查GPU和CUDA
- 🔍 检查所有依赖库
- 🔍 检查CUDA加速模块
- 🧪 运行功能测试
- 📊 生成统计报告

**使用方法**：
```bash
# 1. 激活conda环境
conda activate hstu_a100

# 2. 运行验证脚本
bash check_env.sh

# 3. 查看输出结果
# ✓ 表示通过
# ✗ 表示失败 (会显示错误信息)
```

**输出示例**：
```
=====================================
A100环境验证脚本
=====================================

✓ Conda环境: hstu_a100

=====================================
1. 系统环境检查
=====================================

✓ Python版本
  Python 3.10.12

=====================================
2. GPU和CUDA检查
=====================================

✓ PyTorch
  版本: 2.4.0+cu121
  编译CUDA: 12.1

✓ CUDA可用性
  CUDA可用

✓ GPU信息
  GPU名称: NVIDIA A100-SXM4-40GB
  计算能力: 8.0
  GPU数量: 1

✓ A100检测
  A100 GPU (SM 8.0)

... (更多检查项)

=====================================
6. 统计结果
=====================================

总计: 11
通过: 11

🎉 所有检查通过！环境配置完成！

下一步:
1. 准备数据: python preprocessor.py --dataset_name ml-20m
2. 开始训练: torchrun pretrain_gr_ranking.py ...
```

**适用场景**：
- 安装完成后验证
- 定期检查环境状态
- 排查运行问题
- 切换机器后验证

---

## 🎯 快速开始指南

### 场景1: 我是新手，第一次配置

```bash
# 步骤1: 阅读"完整教程"的前3节，了解基础概念
打开 A100环境配置完整教程.md
阅读第1-3节

# 步骤2: 运行自动化安装脚本
bash install_a100_env.sh

# 步骤3: 验证安装
conda activate hstu_a100
bash check_env.sh

# 步骤4: 如果遇到问题，查看"完整教程"的第10节
```

---

### 场景2: 我熟悉Linux，想快速配置

```bash
# 直接运行自动化脚本
bash install_a100_env.sh

# 验证
conda activate hstu_a100
bash check_env.sh

# 遇到问题时查看"快速参考"
```

---

### 场景3: 自动化脚本失败了，我需要手动配置

```bash
# 步骤1: 打开完整教程
打开 A100环境配置完整教程.md

# 步骤2: 按照教程手动执行每一步
# 推荐从第2节开始 (假设GPU已有)

# 步骤3: 每完成一个大步骤，运行验证
bash check_env.sh

# 步骤4: 遇到具体错误，查看第10节"常见问题排查"
```

---

### 场景4: 我已经有部分环境，只需要编译CUDA模块

```bash
# 步骤1: 检查当前环境
bash check_env.sh

# 步骤2: 根据失败项，查看"快速参考"中的对应命令
打开 快速参考.md
查找"手动安装步骤"中的对应步骤

# 步骤3: 执行缺失的步骤

# 步骤4: 再次验证
bash check_env.sh
```

---

## ❓ 常见问题

### Q1: 我应该先看哪个文档？

**A**: 
- **新手**: 先看《A100环境配置完整教程.md》的前几节，了解基础概念
- **有经验**: 直接运行 `install_a100_env.sh`，遇到问题再看文档
- **排查问题**: 看《完整教程》的第10节"常见问题排查"

---

### Q2: 自动化脚本和手动安装有什么区别？

**A**: 
- **自动化脚本**: 快速、省时、适合标准配置
- **手动安装**: 灵活、可定制、适合特殊需求或排查问题

两者安装的内容完全一样，只是执行方式不同。

---

### Q3: 我的GPU不是A100，可以用这些文档吗？

**A**: 
这些文档专门为A100优化，但核心流程适用于其他GPU：
- **A100 (SM 8.0)**: 完全适用 ✅
- **H100 (SM 9.0)**: 需要修改编译参数 (去掉 `HSTU_DISABLE_86OR89`)
- **V100 (SM 7.0)**: 不支持 ❌ (代码已简化，只保留A100)
- **L40 (SM 8.9)**: 需要修改编译参数

---

### Q4: 编译时间太长了，怎么加速？

**A**: 
1. **增加并行度**: `export MAX_JOBS=8` (根据CPU核心数)
2. **使用SSD**: 编译产生大量临时文件
3. **增加内存**: 避免swap，至少64GB
4. **使用ccache**: 缓存编译结果 (高级)

详见《完整教程》第11节"性能优化建议"

---

### Q5: 验证脚本显示某个模块失败，怎么办？

**A**: 
1. 查看错误信息
2. 在《完整教程》第10节中查找对应问题
3. 如果是编译失败，尝试：
   ```bash
   cd <失败模块的目录>
   pip install . --force-reinstall --no-cache-dir
   ```
4. 再次运行 `bash check_env.sh`

---

### Q6: 我应该使用哪个Python版本？

**A**: 
- **推荐**: Python 3.10 (兼容性最好)
- **支持**: Python 3.9, 3.10, 3.11
- **不推荐**: Python 3.12+ (可能有兼容性问题)

---

### Q7: CUDA版本应该选择哪个？

**A**: 
- **推荐**: CUDA 12.1 (性能好、稳定)
- **支持**: CUDA 11.6 - 12.x
- **注意**: PyTorch版本要匹配CUDA版本

详见《完整教程》第2节和第4节

---

### Q8: 编译时内存不足怎么办？

**A**: 
```bash
# 减少并行编译任务数
export MAX_JOBS=2
export NVCC_THREADS=2

# 关闭其他程序
# 使用swap (临时方案，会很慢)

# 重新编译
cd corelib/hstu
pip install . --force-reinstall --no-cache-dir
```

详见《完整教程》第10.7节

---

### Q9: 子模块初始化失败怎么办？

**A**: 
```bash
# 方法1: 重新初始化
cd /path/to/recsys-examples-main
git submodule update --init --recursive --force

# 方法2: 手动克隆 (如果git子模块有问题)
cd third_party
git clone https://github.com/NVIDIA/cutlass.git
git clone https://github.com/NVIDIA-Merlin/HierarchicalKV.git
```

---

### Q10: 训练时CUDA内存不足怎么办？

**A**: 
```bash
# 编辑gin配置文件
vim movielen_ranking.gin

# 修改以下参数
DataArgs.train_batch_size = 16  # 减小batch size
TrainingArgs.bf16 = True        # 启用混合精度
TrainingArgs.gradient_accumulation_steps = 4  # 梯度累积
```

详见《完整教程》第10.1节

---

## 📊 配置流程图

```
开始
  ↓
检查硬件 (GPU是否为A100?)
  ↓ 是
检查CUDA (版本 >= 11.6?)
  ↓ 是
选择配置方式
  ↓
  ├─→ 自动化安装
  │     ↓
  │   bash install_a100_env.sh
  │     ↓
  │   等待1.5-2小时
  │     ↓
  │   (自动验证)
  │
  └─→ 手动安装
        ↓
      按《完整教程》逐步执行
        ↓
      每步完成后验证
  ↓
bash check_env.sh
  ↓
全部通过? ─→ 否 ─→ 查看《完整教程》第10节排查
  ↓ 是
准备数据
  ↓
开始训练
  ↓
完成！
```

---

## 🔗 相关链接

### 项目文档
- [主README](../../README.md)
- [HSTU Example README](../../examples/hstu/README.md)
- [HSTU Attention README](../../corelib/hstu/README.md)
- [Dynamic Embeddings README](../../corelib/dynamicemb/README.md)

### 外部资源
- [PyTorch官方文档](https://pytorch.org/docs/stable/index.html)
- [NVIDIA CUDA文档](https://docs.nvidia.com/cuda/)
- [NVIDIA CUTLASS](https://github.com/NVIDIA/cutlass)
- [TorchRec文档](https://pytorch.org/torchrec/)
- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM)

---

## 📝 文档版本

| 版本 | 日期 | 说明 |
|------|------|------|
| v1.0 | 2025-11-02 | 初始版本，包含完整教程、快速参考、自动化脚本 |

---

## 💬 获取帮助

如果您在配置过程中遇到问题：

1. **首先**: 查看《完整教程》第10节"常见问题排查"
2. **其次**: 运行 `bash check_env.sh` 查看具体哪个环节出问题
3. **然后**: 在《快速参考》中查找对应命令
4. **最后**: 如果仍未解决，提issue或寻求技术支持

---

**祝您配置顺利！** 🚀

如有任何问题或建议，欢迎反馈！

