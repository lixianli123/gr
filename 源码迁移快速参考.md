# 🚀 源码迁移快速参考卡片

## ⚡ 一键迁移 (最快)

```bash
# 1. 下载脚本
wget https://your-server/copy_source_files.sh
# 或使用已有脚本: copy_source_files.sh

# 2. 运行迁移 (修改路径)
bash copy_source_files.sh /path/to/recsys-examples-main ./accelerated_modules

# 3. 进入新项目
cd accelerated_modules

# 4. 初始化子模块
git init
git submodule add https://github.com/NVIDIA/cutlass.git third_party/cutlass
git submodule add https://github.com/NVIDIA-Merlin/HierarchicalKV.git third_party/HierarchicalKV
git submodule update --init --recursive

# 5. 配置环境
conda create -n accel_modules python=3.10 -y
conda activate accel_modules
pip install torch --index-url https://download.pytorch.org/whl/cu121
source env.sh

# 6. 编译 (约40-80分钟)
bash build.sh

# 7. 测试
python tests/test_hstu_attention.py
python tests/test_dynamicemb.py

# ✓ 完成！
```

---

## 📁 迁移后的目录结构

```
accelerated_modules/
├── hstu_attn/                  # HSTU Attention
│   ├── csrc/                   # C++/CUDA源码
│   │   ├── hstu_api.cpp
│   │   └── src/
│   │       ├── hstu_fwd.h
│   │       ├── hstu_bwd.h
│   │       └── ...
│   ├── __init__.py
│   ├── interface.py
│   └── setup.py
│
├── dynamicemb/                 # Dynamic Embeddings
│   ├── src/                    # CUDA源码
│   │   ├── dynamic_emb_op.cu
│   │   ├── lookup_forward.cu
│   │   └── ...
│   ├── python/                 # Python接口
│   │   ├── __init__.py
│   │   ├── batched_dynamicemb_tables.py
│   │   └── ...
│   └── setup.py
│
├── third_party/                # 第三方依赖
│   ├── cutlass/                # NVIDIA CUTLASS
│   └── HierarchicalKV/         # HierarchicalKV
│
├── tests/                      # 测试
│   ├── test_hstu_attention.py
│   └── test_dynamicemb.py
│
├── examples/                   # 示例
│   └── simple_usage.py
│
├── build.sh                    # 编译脚本
├── env.sh                      # 环境配置
├── requirements.txt            # Python依赖
└── README.md                   # 说明文档
```

---

## 🔑 核心命令

### 编译

```bash
# 配置环境变量
source env.sh

# 一键编译
bash build.sh

# 或分步编译
cd hstu_attn && pip install . --no-deps && cd ..
cd dynamicemb && pip install . --no-deps && cd ..
```

### 测试

```bash
# 测试HSTU
python tests/test_hstu_attention.py

# 测试DynamicEmb
python tests/test_dynamicemb.py

# 运行示例
python examples/simple_usage.py
```

### 使用

```python
# 在你的代码中
from hstu_attn import hstu_attn_varlen_func
from dynamicemb import DynamicEmbeddingBagCollection

# HSTU Attention
output = hstu_attn_varlen_func(q, k, v, cu_seqlens, cu_seqlens, max_seqlen, max_seqlen)

# Dynamic Embeddings
ebc = DynamicEmbeddingBagCollection(tables=[...], device="cuda:0")
```

---

## 📝 需要的文件清单

### 从源项目拷贝 (自动化脚本已包含)

```bash
# HSTU Attention (约10个文件)
corelib/hstu/csrc/hstu_attn/hstu_api.cpp
corelib/hstu/csrc/hstu_attn/src/*.h  (7个头文件)
corelib/hstu/hstu_attn/__init__.py
corelib/hstu/hstu_attn/hstu_attn_interface.py
corelib/hstu/setup.py

# Dynamic Embeddings (约60个文件)
corelib/dynamicemb/src/*.cu, *.cpp, *.h  (约25个)
corelib/dynamicemb/src/hkv_variable_instantiations/*.cu  (18个)
corelib/dynamicemb/dynamicemb/*.py  (约15个)
corelib/dynamicemb/setup.py
corelib/dynamicemb/version.txt

# 第三方依赖 (通过git submodule)
third_party/cutlass/  (NVIDIA CUTLASS)
third_party/HierarchicalKV/  (HierarchicalKV)
```

---

## ⚙️ 编译环境要求

### 硬件

- ✅ NVIDIA A100 GPU (SM 8.0)
- ✅ 32+ GB RAM
- ✅ 6+ GB 磁盘空间

### 软件

```bash
# 系统
Ubuntu 20.04/22.04 或 CentOS 7/8

# CUDA
CUDA >= 11.6 (推荐 12.1)
nvcc --version

# 编译工具
gcc >= 7.5
cmake >= 3.18
ninja

# Python
Python >= 3.9 (推荐 3.10)
PyTorch >= 2.0.0 (with CUDA)
TorchRec >= 1.2.0
```

---

## 🔧 关键环境变量

```bash
# 在 env.sh 中设置

# CUDA路径
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# 编译选项
export TORCH_CUDA_ARCH_LIST="8.0"     # 只编译A100
export MAX_JOBS=4                     # 并行数
export NVCC_THREADS=4

# HSTU优化
export HSTU_DISABLE_86OR89=TRUE
export HSTU_DISABLE_ARBITRARY=TRUE
export HSTU_DISABLE_LOCAL=TRUE
export HSTU_DISABLE_RAB=TRUE
export HSTU_DISABLE_DRAB=TRUE
```

---

## ⏱️ 时间和资源估算

| 步骤 | 时间 | 说明 |
|------|------|------|
| 拷贝源文件 | 2分钟 | 自动脚本 |
| 初始化子模块 | 5分钟 | git submodule |
| 配置环境 | 10分钟 | conda + pip |
| 编译HSTU | 30-60分钟 | CUTLASS编译 |
| 编译DynamicEmb | 10-20分钟 | CUDA编译 |
| 测试验证 | 5分钟 | 运行测试 |
| **总计** | **~1-2小时** | 一次性操作 |

**磁盘空间**:
- 源码: ~100 MB
- 子模块: ~550 MB
- 编译产物: ~3-5 GB
- 总计: ~4-6 GB

**内存需求**:
- 编译时: 32-64 GB RAM
- 运行时: 40 GB GPU + 8 GB RAM

---

## 🐛 常见问题快速解决

### 1. 子模块初始化失败

```bash
# 手动克隆
cd third_party
git clone https://github.com/NVIDIA/cutlass.git
git clone https://github.com/NVIDIA-Merlin/HierarchicalKV.git
```

### 2. 编译时内存不足

```bash
# 减少并行数
export MAX_JOBS=2
export NVCC_THREADS=2
bash build.sh
```

### 3. 找不到CUDA

```bash
# 设置CUDA路径
export CUDA_HOME=/usr/local/cuda-12.1
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

### 4. PyTorch CUDA版本不匹配

```bash
# 重新安装匹配的PyTorch
pip uninstall torch -y
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### 5. 导入模块失败

```python
# 检查安装
pip list | grep hstu
pip list | grep dynamicemb

# 重新安装
cd hstu_attn && pip install . --force-reinstall
cd ../dynamicemb && pip install . --force-reinstall
```

---

## 📊 方案对比

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| **Wheel包** | ⭐⭐⭐⭐⭐ 最简单<br>2步完成 | 版本固定<br>无法修改 | 快速使用<br>不需要修改 |
| **源码迁移** | ⭐⭐⭐⭐ 完全控制<br>可修改代码 | 需要编译<br>时间较长 | 深度定制<br>研究学习 |
| **直接使用** | ⭐⭐⭐ 无需迁移 | 依赖原项目<br>不够独立 | 临时测试<br>快速验证 |

---

## ✅ 验证检查清单

安装完成后，运行以下检查：

```bash
# 1. 检查文件结构
ls -la accelerated_modules/
ls -la accelerated_modules/hstu_attn/
ls -la accelerated_modules/dynamicemb/
ls -la accelerated_modules/third_party/cutlass/include/

# 2. 检查Python导入
python -c "from hstu_attn import hstu_attn_varlen_func; print('HSTU OK')"
python -c "from dynamicemb import DynamicEmbeddingBagCollection; print('DynamicEmb OK')"

# 3. 检查CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"
python -c "import torch; print(f'Compute: {torch.cuda.get_device_capability(0)}')"

# 4. 运行测试
python tests/test_hstu_attention.py
python tests/test_dynamicemb.py

# 5. 运行示例
python examples/simple_usage.py

# ✓ 全部通过说明安装成功
```

---

## 📚 相关文档

- **详细方案**: `源码级迁移完整方案.md` (本文档的详细版)
- **Wheel方案**: `模块迁移指南.md` (更简单的wheel包方案)
- **模型结构**: `Ranking模型结构详解.md` + `Retrieval召回模型结构详解.md`
- **CUDA加速**: `CUDA加速详解.md`
- **环境配置**: `A100环境配置完整教程.md`

---

## 🎯 核心要点

1. ✅ **自动化脚本** - `copy_source_files.sh` 一键完成文件拷贝
2. ✅ **Git子模块** - CUTLASS和HKV通过submodule管理
3. ✅ **独立编译** - `build.sh` 自动编译两个模块
4. ✅ **环境隔离** - 使用conda环境，不影响系统
5. ✅ **完整测试** - 提供测试和示例代码
6. ✅ **清晰文档** - README和注释完整

---

**总结**: 从源码迁移是最灵活的方案，虽然需要编译时间，但能完全控制代码，适合需要深度定制的场景。使用自动化脚本可以大大简化迁移流程！🚀

