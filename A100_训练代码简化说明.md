# A100 HSTU 训练代码 - 深度简化版

## 🎯 简化目标

本次深度简化专注于**保留核心训练流程**，删除所有非训练相关代码：
- ✅ 保留数据加载和处理
- ✅ 保留模型训练核心逻辑
- ✅ 保留 A100 CUDA 加速的 FUSED 层
- ❌ 删除测试、调试、基准测试代码
- ❌ 删除推理相关代码
- ❌ 删除其他后端和层类型

## 📊 简化统计

### 删除的目录（整个目录）
1. ✅ `test/` - 所有测试代码（20+ 文件）
2. ✅ `benchmark/` - 性能测试代码（10+ 文件）
3. ✅ `modules/debug/` - 调试模块
4. ✅ `figs/` - 文档图片
5. ✅ `ops/pt_ops/` - PyTorch 后端实现
6. ✅ `corelib/hstu/hopper/` - H100/H200 支持

### 删除的文件
**推理相关**:
- `inference_gr_ranking.py`
- `kuairand_1k_inference_ranking.gin`
- `configs/inference_config.py`
- `model/inference_ranking_gr.py`
- `modules/gpu_kv_cache_manager.py`
- `modules/host_kv_storage_manager.py`
- `modules/hstu_block_inference.py`
- `modules/inference_embedding.py`
- `modules/paged_hstu_infer_layer.py`
- `dataset/inference_dataset.py`
- `dataset/random_inference_dataset.py`
- `ops/cuda_ops/csrc/paged_kvcache_ops_cuda.cpp`
- `ops/cuda_ops/csrc/paged_kvcache_ops_kernel.cu`

**非必要层实现**:
- `modules/native_hstu_layer.py` - Native 层（支持TP但性能不如FUSED）
- `modules/debug/debug_hstu_layer.py` - 调试层

**非必要后端**:
- `ops/triton_ops/triton_hstu_attention.py` - Triton attention
- `ops/pt_ops/` 目录 - PyTorch 实现（全部）

**配置文件**:
- `prefetch_pipeline_demo.gin`
- `benchmark_ranking.gin`
- `test_utils.py`

### 简化的代码

#### `modules/hstu_block.py`
**之前**: 支持 FUSED、NATIVE、DEBUG 三种层类型
```python
HSTULayerImpl = (
    FusedHSTULayer
    if config.hstu_layer_type == HSTULayerType.FUSED
    else DebugHSTULayer
    if config.hstu_layer_type == HSTULayerType.DEBUG
    else NativeHSTULayer
)
```

**之后**: 只支持 FUSED 层
```python
# Only FusedHSTULayer is supported for A100 GPU
self._attention_layers = torch.nn.ModuleList(
    [FusedHSTULayer(config) for _ in range(self.config.num_layers)]
)
```

#### `configs/hstu_config.py`
**之前**: 三种层类型
```python
class HSTULayerType(Enum):
    FUSED = "FUSED"
    NATIVE = "NATIVE"
    DEBUG = "DEBUG"
```

**之后**: 只有 FUSED
```python
class HSTULayerType(Enum):
    """For A100 GPU, only FUSED type is supported."""
    FUSED = "FUSED"
```

#### `training/utils.py`
添加 Tensor Parallel 检查：
```python
# Check tensor parallel size compatibility
if tensor_model_parallel_args.tensor_model_parallel_size > 1:
    raise ValueError(
        "FusedHSTULayer does not support tensor model parallel > 1. "
        "For A100 GPU, please use tensor_model_parallel_size=1"
    )
```

## 📁 保留的核心结构

```
examples/hstu/
├── pretrain_gr_ranking.py      # ✅ Ranking 训练入口
├── pretrain_gr_retrieval.py    # ✅ Retrieval 训练入口
├── configs/
│   ├── hstu_config.py          # ✅ HSTU 配置（简化）
│   └── task_config.py          # ✅ 任务配置
├── model/
│   ├── ranking_gr.py           # ✅ Ranking 模型
│   └── retrieval_gr.py         # ✅ Retrieval 模型
├── modules/
│   ├── hstu_attention.py       # ✅ HSTU 注意力（仅A100）
│   ├── fused_hstu_layer.py     # ✅ 融合层（A100优化）
│   ├── hstu_block.py           # ✅ HSTU Block（简化）
│   ├── embedding.py            # ✅ Embedding 层
│   ├── mlp.py                  # ✅ MLP 层
│   └── ...                     # ✅ 其他必要模块
├── ops/
│   ├── fused_hstu_op.py        # ✅ 融合操作（A100）
│   ├── cuda_ops/               # ✅ CUDA 操作
│   └── triton_ops/             # ✅ Triton 辅助操作
├── dataset/
│   ├── sequence_dataset.py     # ✅ 序列数据集
│   ├── dummy_dataset.py        # ✅ 测试数据集
│   └── utils.py                # ✅ 数据工具
├── training/
│   ├── training.py             # ✅ 训练逻辑
│   ├── utils.py                # ✅ 训练工具（简化）
│   └── gin_config_args.py      # ✅ Gin 配置
├── distributed/
│   └── sharding.py             # ✅ 分布式分片
├── pipeline/
│   └── train_pipeline.py       # ✅ 训练 Pipeline
└── *.gin                       # ✅ 配置文件
```

## 🚀 使用方法

### 基本要求
- **GPU**: NVIDIA A100 (必须)
- **Tensor Parallel**: 只支持 `tensor_model_parallel_size=1`
- **Layer Type**: 自动使用 FUSED
- **Backend**: 自动使用 CUTLASS

### 配置文件设置

所有 `.gin` 配置文件中：

```python
# 后端（必须）
NetworkArgs.kernel_backend = "cutlass"

# Tensor Parallel（必须是1）
TensorModelParallelArgs.tensor_model_parallel_size = 1

# 数据类型（推荐）
NetworkArgs.dtype_str = "bfloat16"
```

### 运行训练

**Ranking 任务**:
```bash
torchrun --nproc_per_node=1 examples/hstu/pretrain_gr_ranking.py \
    --gin-config-file=examples/hstu/kuairand_1k_ranking.gin
```

**Retrieval 任务**:
```bash
torchrun --nproc_per_node=1 examples/hstu/pretrain_gr_retrieval.py \
    --gin-config-file=examples/hstu/movielen_retrieval.gin
```

## ⚠️ 限制说明

### 不再支持的功能

1. **推理功能** ❌
   - 所有推理相关代码已删除
   - 如需推理，使用原版代码

2. **Tensor Parallel > 1** ❌
   - FusedHSTULayer 不支持 TP
   - 必须设置 `tensor_model_parallel_size=1`

3. **其他层类型** ❌
   - 不支持 NATIVE 层
   - 不支持 DEBUG 层
   - 自动使用 FUSED 层

4. **测试和调试工具** ❌
   - 所有测试代码已删除
   - 调试层已删除
   - 基准测试已删除

5. **非A100 GPU** ❌
   - 启动时会检测 GPU
   - 非 A100 立即报错

## 🎯 优化效果

### 代码量变化
- **删除文件**: 50+ 个
- **删除目录**: 6 个
- **删除代码行数**: 约 1000+ 行
- **保留核心代码**: 约 3000 行

### 简化程度
- **层类型**: 3 种 → 1 种 (-66%)
- **后端选项**: 3 种 → 1 种 (-66%)
- **GPU 支持**: 多种 → 1 种 (-75%)
- **功能范围**: 训练+推理 → 仅训练 (-50%)

### 运行效果
- ✅ **启动更快**: 减少模块导入和初始化
- ✅ **代码更清晰**: 无分支判断，直接执行
- ✅ **配置更简单**: 更少的选项，更少的错误
- ✅ **性能无损**: 使用的就是原有最优路径

## 🔍 核心流程

### 训练流程（简化版）

```python
# 1. GPU 检测
check_a100_gpu()  # 必须是 A100

# 2. 初始化
init.initialize_distributed()
init.initialize_model_parallel(tensor_model_parallel_size=1)

# 3. 创建配置
hstu_config = create_hstu_config(network_args, tp_args)
# 自动设置: kernel_backend=CUTLASS, layer_type=FUSED

# 4. 创建模型
model = get_ranking_model(hstu_config, task_config)
# 使用 FusedHSTULayer (A100优化)

# 5. 训练
train_with_pipeline(pipeline, ...)
```

### 数据流

```
Dataset → DataLoader → Embedding → HSTUBlock → Task Head → Loss
                                      ↓
                                  FusedHSTULayer (CUTLASS A100)
                                      ↓
                               fused_hstu_op.py
                                      ↓
                            hstu_attn_2_cuda (C++/CUDA)
```

## 📝 配置示例

### Ranking 任务配置
```python
# kuairand_1k_ranking.gin

# 数据集
DatasetArgs.dataset_name = "kuairand-1k"
DatasetArgs.max_sequence_length = 50

# 网络（自动使用 CUTLASS + FUSED）
NetworkArgs.kernel_backend = "cutlass"
NetworkArgs.dtype_str = "bfloat16"
NetworkArgs.num_layers = 4
NetworkArgs.hidden_size = 256

# Tensor Parallel（必须是1）
TensorModelParallelArgs.tensor_model_parallel_size = 1

# 训练
TrainerArgs.train_batch_size = 128
TrainerArgs.max_train_iters = 10000
```

## 💡 最佳实践

1. **GPU 选择**: 确保使用 A100
2. **Batch Size**: 根据显存调整（A100 有 40GB/80GB）
3. **混合精度**: 使用 `bfloat16` 获得最佳性能
4. **单卡训练**: 设置 `tensor_model_parallel_size=1`
5. **数据准备**: 确保数据格式正确

## 🐛 常见错误

### 错误 1: 非 A100 GPU
```
RuntimeError: This code is optimized for A100 GPU (SM 8.0) only.
```
**解决**: 必须使用 A100 GPU

### 错误 2: Tensor Parallel > 1
```
ValueError: FusedHSTULayer does not support tensor model parallel > 1.
```
**解决**: 设置 `tensor_model_parallel_size=1`

### 错误 3: 非 CUTLASS 后端
```
ValueError: Only CUTLASS backend is supported for A100 GPU.
```
**解决**: 设置 `NetworkArgs.kernel_backend = "cutlass"`

## 📚 相关文档

- `REFACTORING_SUMMARY.md` - 第一次重构说明
- `CHANGES.md` - 详细改动清单
- `A100_使用指南.md` - 快速使用指南

## 🎉 总结

此版本代码：
- ✅ **极度简化**: 删除了 1000+ 行代码
- ✅ **专注训练**: 只保留训练相关功能
- ✅ **A100 优化**: 使用 FUSED 层 + CUTLASS
- ✅ **易于理解**: 代码结构清晰，无分支
- ✅ **性能最优**: 保留的就是最优路径

**适用场景**: A100 GPU 上的模型训练
**不适用**: 推理、其他 GPU、调试测试

---

**简化日期**: 2025-11-02  
**版本**: Deep Simplified v2.0

