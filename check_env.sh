#!/bin/bash
# ============================================
# A100ç¯å¢ƒéªŒè¯è„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash check_env.sh
# ============================================

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}=====================================${NC}"
echo -e "${BLUE}A100ç¯å¢ƒéªŒè¯è„šæœ¬${NC}"
echo -e "${BLUE}=====================================${NC}"
echo ""

# æ£€æŸ¥condaç¯å¢ƒ
if [ -z "$CONDA_DEFAULT_ENV" ]; then
    echo -e "${RED}âœ— Condaç¯å¢ƒæœªæ¿€æ´»${NC}"
    echo "  è¯·å…ˆè¿è¡Œ: conda activate hstu_a100"
    exit 1
fi

echo -e "${GREEN}âœ“ Condaç¯å¢ƒ: $CONDA_DEFAULT_ENV${NC}"
echo ""

# è¿è¡ŒPythonéªŒè¯
python << 'EOF'
import sys

# é¢œè‰²ä»£ç 
RED = '\033[0;31m'
GREEN = '\033[0;32m'
YELLOW = '\033[1;33m'
BLUE = '\033[0;34m'
NC = '\033[0m'

def print_header(text):
    print(f"{BLUE}{'=' * 45}{NC}")
    print(f"{BLUE}{text}{NC}")
    print(f"{BLUE}{'=' * 45}{NC}")

def check(name, func, details=None):
    """æ£€æŸ¥å•ä¸ªç»„ä»¶"""
    try:
        result = func()
        if details:
            print(f"{GREEN}âœ“ {name}{NC}")
            if isinstance(result, dict):
                for key, value in result.items():
                    print(f"  {key}: {value}")
            else:
                print(f"  {result}")
        else:
            print(f"{GREEN}âœ“ {name}{NC}")
        return True
    except Exception as e:
        print(f"{RED}âœ— {name}{NC}")
        print(f"  é”™è¯¯: {e}")
        return False

print_header("1. ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥")
print("")

# Pythonç‰ˆæœ¬
def check_python():
    return f"Python {sys.version.split()[0]}"

check("Pythonç‰ˆæœ¬", check_python, details=True)

# ============================================
print("")
print_header("2. GPUå’ŒCUDAæ£€æŸ¥")
print("")

# PyTorch
def check_pytorch():
    import torch
    return {
        "ç‰ˆæœ¬": torch.__version__,
        "ç¼–è¯‘CUDA": torch.version.cuda,
    }

passed_torch = check("PyTorch", check_pytorch, details=True)

# CUDAå¯ç”¨æ€§
def check_cuda():
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("CUDAä¸å¯ç”¨")
    return "CUDAå¯ç”¨"

passed_cuda = check("CUDAå¯ç”¨æ€§", check_cuda, details=True)

# GPUä¿¡æ¯
def check_gpu():
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("CUDAä¸å¯ç”¨")
    
    gpu_name = torch.cuda.get_device_name(0)
    compute_cap = torch.cuda.get_device_capability(0)
    gpu_count = torch.cuda.device_count()
    
    return {
        "GPUåç§°": gpu_name,
        "è®¡ç®—èƒ½åŠ›": f"{compute_cap[0]}.{compute_cap[1]}",
        "GPUæ•°é‡": gpu_count,
    }

passed_gpu = check("GPUä¿¡æ¯", check_gpu, details=True)

# A100æ£€æµ‹
def check_a100():
    import torch
    compute_cap = torch.cuda.get_device_capability(0)
    if compute_cap != (8, 0):
        raise RuntimeError(f"ä¸æ˜¯A100 GPU (è®¡ç®—èƒ½åŠ›: {compute_cap})")
    return "A100 GPU (SM 8.0)"

passed_a100 = check("A100æ£€æµ‹", check_a100, details=True)

# ============================================
print("")
print_header("3. åŸºç¡€ä¾èµ–æ£€æŸ¥")
print("")

# FBGEMM_GPU
def check_fbgemm():
    import fbgemm_gpu
    return f"ç‰ˆæœ¬: {fbgemm_gpu.__version__}"

passed_fbgemm = check("FBGEMM_GPU", check_fbgemm, details=True)

# TorchRec
def check_torchrec():
    import torchrec
    return f"ç‰ˆæœ¬: {torchrec.__version__}"

passed_torchrec = check("TorchRec", check_torchrec, details=True)

# Megatron-Core
def check_megatron():
    import megatron
    from megatron.core import parallel_state
    return "å·²å®‰è£…"

passed_megatron = check("Megatron-Core", check_megatron, details=True)

# å…¶ä»–ä¾èµ–
def check_others():
    import gin
    import torchmetrics
    import einops
    return "gin-config, torchmetrics, einops"

check("å…¶ä»–ä¾èµ–", check_others, details=True)

# ============================================
print("")
print_header("4. CUDAåŠ é€Ÿæ¨¡å—æ£€æŸ¥")
print("")

# HSTU Attention
def check_hstu_attn():
    import hstu_attn
    return "CUTLASSå†…æ ¸"

passed_hstu = check("HSTU Attention", check_hstu_attn, details=True)

# DynamicEmb
def check_dynamicemb():
    import dynamicemb
    return f"ç‰ˆæœ¬: {dynamicemb.__version__}"

passed_dynamicemb = check("Dynamic Embeddings", check_dynamicemb, details=True)

# HSTU CUDA Ops
def check_hstu_ops():
    import hstu_cuda_ops
    return "Jagged Tensorç®—å­"

passed_ops1 = check("HSTU CUDA Ops", check_hstu_ops, details=True)

# Paged KVCache Ops
def check_kvcache_ops():
    import paged_kvcache_ops
    return "Paged KVCacheç®—å­"

passed_ops2 = check("Paged KVCache Ops", check_kvcache_ops, details=True)

# ============================================
print("")
print_header("5. åŠŸèƒ½æµ‹è¯•")
print("")

# HSTU Attentionå‰å‘ä¼ æ’­æµ‹è¯•
def test_hstu_forward():
    import torch
    from hstu_attn import hstu_attn_varlen_func
    
    batch_size = 2
    nheads = 8
    headdim = 64
    seqlen = 100
    
    q = torch.randn(batch_size * seqlen, nheads, headdim, dtype=torch.float16).cuda()
    k = torch.randn(batch_size * seqlen, nheads, headdim, dtype=torch.float16).cuda()
    v = torch.randn(batch_size * seqlen, nheads, headdim, dtype=torch.float16).cuda()
    cu_seqlens = torch.tensor([0, seqlen, 2*seqlen], dtype=torch.int32).cuda()
    
    out = hstu_attn_varlen_func(
        q, k, v,
        cu_seqlens, cu_seqlens,
        seqlen, seqlen
    )
    
    return f"è¾“å‡ºshape: {out.shape}, dtype: {out.dtype}"

check("HSTU Attentionå‰å‘ä¼ æ’­", test_hstu_forward, details=True)

# Dynamic Embeddingsæµ‹è¯•
def test_dynamicemb():
    import torch
    from torchrec import EmbeddingBagConfig
    # åªæ£€æŸ¥å¯¼å…¥ï¼Œä¸å®é™…åˆ›å»º (é¿å…åˆå§‹åŒ–å¼€é”€)
    return "å¯¼å…¥æˆåŠŸ"

check("Dynamic Embeddingså¯¼å…¥", test_dynamicemb, details=True)

# ============================================
print("")
print_header("6. ç»Ÿè®¡ç»“æœ")
print("")

checks = [
    passed_torch,
    passed_cuda,
    passed_gpu,
    passed_a100,
    passed_fbgemm,
    passed_torchrec,
    passed_megatron,
    passed_hstu,
    passed_dynamicemb,
    passed_ops1,
    passed_ops2,
]

total = len(checks)
passed = sum(checks)
failed = total - passed

print(f"æ€»è®¡: {total}")
print(f"{GREEN}é€šè¿‡: {passed}{NC}")
if failed > 0:
    print(f"{RED}å¤±è´¥: {failed}{NC}")

print("")
if passed == total:
    print(f"{GREEN}ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒé…ç½®å®Œæˆï¼{NC}")
    print("")
    print("ä¸‹ä¸€æ­¥:")
    print("1. å‡†å¤‡æ•°æ®: python preprocessor.py --dataset_name ml-20m")
    print("2. å¼€å§‹è®­ç»ƒ: torchrun pretrain_gr_ranking.py --gin-config-file movielen_ranking.gin")
    sys.exit(0)
else:
    print(f"{RED}âŒ éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°é”™è¯¯ä¿¡æ¯è¿›è¡Œä¿®å¤{NC}")
    print("")
    print("å¸¸è§é—®é¢˜æ’æŸ¥:")
    print("1. æ£€æŸ¥condaç¯å¢ƒæ˜¯å¦æ­£ç¡®æ¿€æ´»")
    print("2. æ£€æŸ¥CUDAå’ŒGPUé©±åŠ¨æ˜¯å¦æ­£å¸¸")
    print("3. æ£€æŸ¥å­æ¨¡å—æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–: git submodule update --init --recursive")
    print("4. é‡æ–°ç¼–è¯‘CUDAæ¨¡å—: cd corelib/hstu && pip install . --force-reinstall")
    print("")
    print("è¯¦ç»†æ•™ç¨‹: A100ç¯å¢ƒé…ç½®å®Œæ•´æ•™ç¨‹.md")
    sys.exit(1)

EOF

